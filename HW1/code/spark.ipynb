{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['cosh', 'sinh', 'trunc', 'tan', 'rand', 'rank', 'sin', 'mean', 'log2', 'expm1', 'rint', 'array', 'size', 'broadcast', 'ceil', 'cos', 'tanh', 'sqrt', 'split', 'randn', 'floor', 'cbrt', 'hypot', 'log', 'log10', 'sum', 'log1p', 'repeat', 'exp']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import rlcompleter, readline\n",
    "readline.parse_and_bind('tab: complete')\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "from pyspark.sql.functions import monotonicallyIncreasingId\n",
    "from pyspark.ml.feature import OneHotEncoder,StringIndexer\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sc.textFile('../dac/train.txt', 10000)\n",
    "sample = sc.textFile('../dac_sample/dac_sample.txt').map(lambda x: x.split('\\t'))\n",
    "sample = sample.map(lambda x: x[1:])\n",
    "split = data.map(lambda x: x.split('\\t'))\n",
    "label = split.map(lambda x: x[0])\n",
    "entire_train = split.map(lambda x: x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train10M, train38M = entire_train.randomSplit([10,38])\n",
    "train5M, validation2M, test3M = train10M.randomSplit([5,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = sqlContext.createDataFrame(train5M, ['C'+str(i) for i in range(39)])\n",
    "df_sample = sqlContext.createDataFrame(sample, ['C'+str(i) for i in range(39)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Convert String Column to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def changeDataType(df):\n",
    "    new = df    \n",
    "    for i in range(13):\n",
    "        new = new.withColumn('C'+str(i), new['C'+str(i)].cast('int'))\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_sample = changeDataType(df_sample)\n",
    "new_train = changeDataType(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def caculateMean(df):\n",
    "    means = []\n",
    "    for i in range(13):\n",
    "        means.append(new_sample.groupBy().mean('C'+str(i)).collect()[0][0])\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[C0: int, C1: int, C2: int, C3: int, C4: int, C5: int, C6: int, C7: int, C8: int, C9: int, C10: int, C11: int, C12: int, C13: string, C14: string, C15: string, C16: string, C17: string, C18: string, C19: string, C20: string, C21: string, C22: string, C23: string, C24: string, C25: string, C26: string, C27: string, C28: string, C29: string, C30: string, C31: string, C32: string, C33: string, C34: string, C35: string, C36: string, C37: string, C38: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = caculateMean(new_sample)\n",
    "new_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculateStd(df):\n",
    "    stds = []\n",
    "    for i in range(13):\n",
    "        std = float(new_sample.describe('C'+str(i)).collect()[2][1])\n",
    "        stds.append(std)\n",
    "    return stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[C0: int, C1: int, C2: int, C3: int, C4: int, C5: int, C6: int, C7: int, C8: int, C9: int, C10: int, C11: int, C12: int, C13: string, C14: string, C15: string, C16: string, C17: string, C18: string, C19: string, C20: string, C21: string, C22: string, C23: string, C24: string, C25: string, C26: string, C27: string, C28: string, C29: string, C30: string, C31: string, C32: string, C33: string, C34: string, C35: string, C36: string, C37: string, C38: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stds = calculateStd(new_sample)\n",
    "new_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Fill in Numeric Missing Value with Mean\n",
    "1) fill in median for numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fillMissing(df):\n",
    "    cols_name = ['C'+str(i) for i in range(13)]\n",
    "    fill_data = means\n",
    "    dic = dict(zip(cols_name,fill_data))\n",
    "    #print dic\n",
    "    new = df.fillna(dic)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filled_numeric = fillMissing(new_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[C0: int, C1: int, C2: int, C3: int, C4: int, C5: int, C6: int, C7: int, C8: int, C9: int, C10: int, C11: int, C12: int, C13: string, C14: string, C15: string, C16: string, C17: string, C18: string, C19: string, C20: string, C21: string, C22: string, C23: string, C24: string, C25: string, C26: string, C27: string, C28: string, C29: string, C30: string, C31: string, C32: string, C33: string, C34: string, C35: string, C36: string, C37: string, C38: string]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def drawHistogram(cols, i):\n",
    "    col = cols[i]\n",
    "    count = col.histogram(col.distinct().count())\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"drawing histogram\"\n",
    "for i in range(13):\n",
    "    print str(i) + \"th col\"\n",
    "    new = drawHistogram(cols, i)\n",
    "    counts.append(new)\n",
    "    plt.bar(new[0][1:], np.log10(new[1]), width = 1)\n",
    "    plt.savefig(\"../images/log_col_\"+str(i)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize(df):\n",
    "    cols = [\"C\"+str(i) for i in range(13)]\n",
    "    for each in cols:\n",
    "        print \"start\" + each\n",
    "        describe = df.describe(each).collect()\n",
    "        mean, std = describe[1][1], describe[2][1]\n",
    "        df = df.withColumn(each, (df[each]-mean)/std)\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standardize_cols = []\n",
    "standardize_cols_sample = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start standardizing\n",
      "startC0\n",
      "startC1\n",
      "startC2\n",
      "startC3\n",
      "startC4\n",
      "startC5\n",
      "startC6\n",
      "startC7\n",
      "startC8\n",
      "startC9\n",
      "startC10\n",
      "startC11\n",
      "startC12\n"
     ]
    }
   ],
   "source": [
    "print \"start standardizing\"\n",
    "standardize_df = standardize(filled_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[C0: double, C1: double, C2: double, C3: double, C4: double, C5: double, C6: double, C7: double, C8: double, C9: double, C10: double, C11: double, C12: double, C13: string, C14: string, C15: string, C16: string, C17: string, C18: string, C19: string, C20: string, C21: string, C22: string, C23: string, C24: string, C25: string, C26: string, C27: string, C28: string, C29: string, C30: string, C31: string, C32: string, C33: string, C34: string, C35: string, C36: string, C37: string, C38: string]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardize_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encoding(df):\n",
    "    cols = [\"C\"+str(i) for i in range(13,39)]\n",
    "    df = df.na.replace('', 'unknown')\n",
    "    for each in cols:\n",
    "        print \"start\"+each\n",
    "        indexer = StringIndexer(inputCol= each, outputCol = \"indexed\"+each)\n",
    "        model = indexer.fit(df)\n",
    "        indexed = model.transform(df)\n",
    "        indexed.drop(each)\n",
    "        encoder = OneHotEncoder(dropLast=False, inputCol=\"indexed\"+each, outputCol=\"encoded\"+each)\n",
    "        encoded = encoder.transform(indexed)\n",
    "        df = encoded\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startC13\n",
      "startC14\n",
      "startC15\n",
      "startC16\n",
      "startC17\n",
      "startC18\n",
      "startC19\n",
      "startC20\n",
      "startC21\n",
      "startC22\n",
      "startC23\n",
      "startC24\n",
      "startC25\n",
      "startC26\n",
      "startC27\n",
      "startC28\n",
      "startC29\n",
      "startC30\n",
      "startC31\n",
      "startC32\n",
      "startC33\n",
      "startC34\n",
      "startC35\n",
      "startC36\n",
      "startC37\n",
      "startC38\n"
     ]
    }
   ],
   "source": [
    "encoded_df = encoding(standardize_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
